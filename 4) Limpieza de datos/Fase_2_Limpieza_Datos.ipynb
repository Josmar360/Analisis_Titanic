{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar bibliotecas que se usaran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abrir el archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los archivos CSV\n",
    "data_old = pd.read_csv(\"Titanic-Dataset-old.csv\")\n",
    "data = pd.read_csv(\"Titanic-Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\tIdentificar y documentar columnas con valores nulos y decidir una estrategia para abordarlas (eliminación, imputación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ver valores nulos\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Eliminar la columna de Cabina\n",
    "data = data.drop('Cabin', axis=1)\n",
    "\n",
    "# Imputar la columna de Edad\n",
    "Imputar = SimpleImputer(strategy='mean')\n",
    "data['Age'] = Imputar.fit_transform(data[['Age']])\n",
    "\n",
    "# Eliminar las dos filas en Embarked\n",
    "data = data.dropna(subset=['Embarked'])\n",
    "\n",
    "# Sobreescribir el archivo CSV\n",
    "data.to_csv(\"Titanic-Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tDecida si ciertas columnas pueden ser innecesarias para el análisis y elimínelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Ticket', axis=1)\n",
    "\n",
    "# Sobreescribir el archivo CSV\n",
    "data.to_csv(\"Titanic-Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\tIdentifique variables categóricas importantes y conviértalas a un formato más manejable (one-hot, asignación de números, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar One-Hot a la variable Sex\n",
    "data = pd.get_dummies(data, columns=['Sex'])\n",
    "\n",
    "# Asignación de números a la variable 'Pclass' (Label Encoding)\n",
    "data['Pclass'] = data['Pclass'].astype('category').cat.codes\n",
    "\n",
    "# Asignación de números a la variable 'Embarked' (Label Encoding)\n",
    "data['Embarked'] = data['Embarked'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\tInvestiga si hay duplicados y decide qué hacer con ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas duplicadas:\n",
      "Empty DataFrame\n",
      "Columns: [PassengerId, Survived, Pclass, Name, Age, SibSp, Parch, Fare, Embarked, Sex_female, Sex_male]\n",
      "Index: []\n",
      "\n",
      "Cantidad total de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicados en todo el conjunto de datos\n",
    "duplicados = data.duplicated()\n",
    "\n",
    "# Imprimir las filas duplicadas\n",
    "print(\"Filas duplicadas:\")\n",
    "print(data[duplicados])\n",
    "\n",
    "# Imprimir la cantidad total de filas duplicadas\n",
    "print(\"\\nCantidad total de filas duplicadas:\", duplicados.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.\tExaminar si los valores agregados se mantienen consistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================ DataSet Viejo ================\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      " ================ DataSet Nuevo ================\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   889.000000  889.000000  889.000000  889.000000  889.000000   \n",
      "mean    446.000000    0.382452    1.311586   29.653446    0.524184   \n",
      "std     256.998173    0.486260    0.834700   12.968366    1.103705   \n",
      "min       1.000000    0.000000    0.000000    0.420000    0.000000   \n",
      "25%     224.000000    0.000000    1.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    2.000000   29.699118    0.000000   \n",
      "75%     668.000000    1.000000    2.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    2.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare    Embarked  \n",
      "count  889.000000  889.000000  889.000000  \n",
      "mean     0.382452   32.096681    1.535433  \n",
      "std      0.806761   49.697504    0.792088  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    7.895800    1.000000  \n",
      "50%      0.000000   14.454200    2.000000  \n",
      "75%      0.000000   31.000000    2.000000  \n",
      "max      6.000000  512.329200    2.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compara los valores agregados\n",
    "print(\"\\n ================ DataSet Viejo ================\")\n",
    "print(data_old.describe())\n",
    "print(\"\\n ================ DataSet Nuevo ================\")\n",
    "print(data.describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
